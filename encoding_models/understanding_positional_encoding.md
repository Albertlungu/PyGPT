<style>
body {
  font-family: "Times New Roman", Times, serif;
  font-size: 16px;
}
</style>


This file is just to help me understand positional encoding and to remind myself if I forget. 

*[See this website for more details](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)*

**What is positional encoding?**
- Positional encoding is a way of representing the position of an object in the input sequence in a way that the model can understand and use both its meaning and its context.
    - This is necessary because the order of words in a sentence matters.
- For future reference, when I refer to dimension, it means the length of a vector

The formulas for positional encoding at a certain position are the following:

$$P(k, 2i) = \text{sin}(\frac{k}{n^{2i/d}})$$

<p style="text-align:center; font-weight: bold">Or, alternatively, for odd indices: </p>

$$P(k, 2i + 1) = \text{cos}(\frac{k}{n^{2i/d}})$$

Where:

ğ‘˜: Position of an object in the input sequence, 0 â‰¤ ğ‘˜ <ğ¿/2
- ğ¿ is the length of the input sequence
    - For example, in the input sequence â€œhelloâ€ (5 characters), ğ¿ = 5, and if ğ‘˜ = 0, the targeted character is *"h"*

ğ‘‘: Dimension of the output embedding space
- i.e. the size of the embedding vector
    - The size of an embedding vector refers to a vector as such: *$$<0.1, 0.513, -0.008, ..., -0.4>$$* with ğ‘‘ being the amount of numbers in that vector (often 128, 256, 512, 768, etc.)

ğ‘ƒâ¡(ğ‘˜,ğ‘—): Position function for mapping a position ğ‘˜ in the input sequence to index (ğ‘˜,ğ‘—) of the positional matrix

ğ‘›: User-defined scalar, set to 10,000 by the authors of [Attention Is All You Need](https://arxiv.org/pdf/1706.03762).
- Basically, it controls the frequency and wavelength of the sine and cosine functions representing the positional encoding
    - Frequencies and wavelengths help to represent the position of the object in the input sequence and its context

ğ‘–: Used for mapping to column indices 0 â‰¤ ğ‘– <ğ‘‘/2, with a single value of ğ‘– maps to both sine and cosine functions
- This last one is in between 0 and d/2 because the first half of the output is the sin values and the second half is the cos values

**Definition of gradient:**
- The direction in which the vector points at the steepest location of a function
    - Remember MHF4U!!! - calc 
    $$\text{max}(f'(x))$$


**Loss function**:
- The loss function is the difference between the predicted output and the true output
    - Often calculated with something such as MSE (mean square error)
    $$MSE = \frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2$$
    *For example (generated by AI):*
    Suppose you want to predict the number of products sold each day at a store, and compare your modelâ€™s predictions with the actual sales.

    | Day | Actual Sales | Predicted Sales | Error (Actual - Predicted) | Squared Error |
    |-----|--------------|----------------|---------------------------|---------------|
    | 1   | 3            | 2              | 1                         | 1             |
    | 2   | 7            | 8              | -1                        | 1             |
    | 3   | 5            | 4              | 1                         | 1             |
    | 4   | 1            | 0              | 1                         | 1             |
    | 5   | 9            | 13             | -4                        | 16            |

    Mean Squared Error (MSE): $$MSE = \frac{1 + 1 + 1 + 1 + 16}{5} = 4$$

    The MSE of 4 shows that, on average, the squared prediction error per day is 4 units. The larger mistake on Day 5 has a much bigger effect on the total loss, highlighting how MSE penalizes larger mistakes more for model training.
